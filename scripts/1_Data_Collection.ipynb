{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-16T02:58:09.304697Z",
     "start_time": "2025-01-16T02:58:09.242703Z"
    }
   },
   "source": [
    "# ################## DELETE SESSION ##################\n",
    "import fiftyone as fo\n",
    "dataset = fo.load_dataset(\"Test\")\n",
    "dataset.delete()\n",
    "# ####################################################"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T02:58:11.127818Z",
     "start_time": "2025-01-16T02:58:11.109820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ################## LIST EXISTING SESSIONS ##################\n",
    "import fiftyone as fo\n",
    "\n",
    "datasets = fo.list_datasets()\n",
    "# dataset = fo.load_dataset(\"images\")\n",
    "print(fo.list_datasets())"
   ],
   "id": "fe944bce9a0bb57f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T02:58:18.239797Z",
     "start_time": "2025-01-16T02:58:13.191809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ################## CREATE NEW SESSION ##################\n",
    "\n",
    "import fiftyone as fo\n",
    "import os\n",
    "\n",
    "name = \"18july\"\n",
    "\n",
    "dataset_dir = \"Path_To_Your_Dataset\"\n",
    "ds_17jul = fo.Dataset.from_dir(\n",
    "    dataset_dir=dataset_dir,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "    name=name,\n",
    "    progress=True\n",
    ")\n",
    "\n",
    "session = fo.launch_app(ds_17jul)\n",
    "\n",
    "ds_17jul.persistent = True"
   ],
   "id": "b7c7149f946b9126",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing samples...\n",
      " 100% |█████████████| 16630/16630 [352.0ms elapsed, 0s remaining, 47.8K samples/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x213fd1f33a0>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=c472f20d-cfcd-42f2-95b1-ea92df8ae6c2\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T02:57:28.426494Z",
     "start_time": "2025-01-16T02:56:54.793550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ################## LOAD CURRENT DATASET VIEW ##################\n",
    "import fiftyone as fo \n",
    "\n",
    "ds_17jul = fo.load_dataset('18july')\n",
    "\n",
    "ds_17jul_session = fo.launch_app(ds_17jul)\n",
    "ds_17jul_session.wait()"
   ],
   "id": "f429cde3d294babc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x213f9ba02b0>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=dd9810d1-a988-4955-9223-74e4d966cab2\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook sessions cannot wait\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T08:53:54.958848Z",
     "start_time": "2025-01-14T07:03:18.738219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ################## EXPORT IMAGES ##################\n",
    "export_ids = ds_17jul_session.view\n",
    "\n",
    "export_ids.export(\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "    export_dir=\"Path_To_Your_Dataset\",\n",
    "    abs_paths=True,\n",
    ")"
   ],
   "id": "c60a3c9fd32aefba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring unsupported parameter 'abs_paths'\n",
      "Exporting samples...\n",
      " 100% |████████████████| 16630/16630 [1.8h elapsed, 0s remaining, 1.9 docs/s]      \n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:50:20.174048Z",
     "start_time": "2025-01-14T08:58:13.492709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ################## RESIZE IMAGES ##################\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "images_path = r\"Path_To_Your_Dataset\"\n",
    "\n",
    "heights = []\n",
    "widths = []\n",
    "\n",
    "for filename in os.listdir(images_path):\n",
    "    if filename.lower().endswith(\".jpg\"):\n",
    "        file_path = os.path.join(images_path, filename)\n",
    "        \n",
    "        try:\n",
    "            with Image.open(file_path) as image:\n",
    "                width, height = image.size\n",
    "                \n",
    "                if height >= 1:\n",
    "                    # Set desired dimensions\n",
    "                    new_height = 640\n",
    "                    new_width = 640\n",
    "                    # Option 1: Maintain aspect ratio\n",
    "                    #a#spect_ratio = width / height\n",
    "                    #new_width = int(new_height * aspect_ratio)\n",
    "                    \n",
    "                    # Option 2: Set width to a specific value\n",
    "                    # new_width = 6300\n",
    "                    # new_height = int(new_width / aspect_ratio)\n",
    "                    \n",
    "                    # Resize the image\n",
    "                    resized_image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "                    \n",
    "                    # Save the resized image\n",
    "                    resized_image.save(file_path)\n",
    "                    \n",
    "                    # Update width and height\n",
    "                    width, height = resized_image.size\n",
    "                \n",
    "                # Append the dimensions to the lists\n",
    "                heights.append(height)\n",
    "                widths.append(width)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "if heights:\n",
    "    print(\"Minimum height:\", min(heights))\n",
    "else:\n",
    "    print(\"Error: No images processed.\")"
   ],
   "id": "de563f06c21abda1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum height: 640\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:38:12.990530Z",
     "start_time": "2025-01-14T01:38:07.248392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Append Label to File Name\n",
    "import os\n",
    "# Rename files to include labels\n",
    "export_ids = ds_17jul_session.view\n",
    "\n",
    "# Mark as errors\n",
    "for sample in export_ids:\n",
    "    original_filename = sample.filepath.split(os.path.sep)[-1]  # Get the original filename\n",
    "    label = sample.ground_truth['label']  # Get the label (adjust if your label field is different)\n",
    "    new_filename = f\"{label}_{original_filename}\"  # Create new filename\n",
    "    old_filepath = f\"Path_To_Your_Dataset\\\\{original_filename}\"\n",
    "    new_filepath = f\"Path_To_Your_Dataset\\\\{new_filename}\"\n",
    "\n",
    "    # Rename the file\n",
    "    if os.path.exists(old_filepath):\n",
    "        os.rename(old_filepath, new_filepath)"
   ],
   "id": "4250d65fa95ff503",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T00:51:36.513170Z",
     "start_time": "2025-01-15T00:51:36.291024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Move Matching Datasets to Another Directory\n",
    "\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Example usage\n",
    "json_file_path = \"Path_To_JSON_File\"  # Path to your JSON file\n",
    "images_directory = \"Path_To_Your_Dataset\"  # Directory containing images\n",
    "output_directory = \"Path_To_Your_Dataset\"  # Directory to move matching files\n",
    "\n",
    "def move_files_from_json(json_file, images_path, output_directory):\n",
    "    \"\"\"\n",
    "    Read names from a JSON file, find matching files in the images_path, and move them to the output directory.\n",
    "\n",
    "    :param json_file: Path to the JSON file containing names to search for.\n",
    "    :param images_path: Path to the directory containing images.\n",
    "    :param output_directory: Path to the directory where matching files should be moved.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Load names from the JSON file\n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading JSON file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Extract names from JSON\n",
    "    if isinstance(data, list):\n",
    "        # Assume JSON contains a list of strings or objects with a 'name' key\n",
    "        names = [item if isinstance(item, str) else item.get('name') for item in data]\n",
    "    else:\n",
    "        print(\"Invalid JSON format. Expected a list of names or objects with 'name' keys.\")\n",
    "        return\n",
    "\n",
    "    # Ensure names are valid strings\n",
    "    names = [name for name in names if isinstance(name, str)]\n",
    "\n",
    "    # Iterate through files in the images_path\n",
    "    for file_name in os.listdir(images_path):\n",
    "        # Check if the file name matches any of the names from the JSON (without extensions)\n",
    "        name_without_extension, _ = os.path.splitext(file_name)\n",
    "        if name_without_extension in names:\n",
    "            source_path = os.path.join(images_path, file_name)\n",
    "            destination_path = os.path.join(output_directory, file_name)\n",
    "            try:\n",
    "                shutil.move(source_path, destination_path)\n",
    "                print(f\"Moved: {file_name} to {output_directory}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error moving file {file_name}: {e}\")\n",
    "\n",
    "move_files_from_json(json_file_path, images_directory, output_directory)\n"
   ],
   "id": "526ed42bf3266385",
   "outputs": [],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
