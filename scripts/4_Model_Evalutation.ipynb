{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T04:14:47.141249Z",
     "start_time": "2025-01-03T04:14:46.626994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generates and Saves Comparison of Original to Heatmaps in .jpg format\n",
    "\n",
    "# Import necessary modules\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from yolo_cam.eigen_cam import EigenCAM\n",
    "from yolo_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# Load your YOLO model\n",
    "model = YOLO('C:\\\\Users\\\\MaxwellLee\\\\PycharmProjects\\\\UVSM\\\\models\\\\best.pt')\n",
    "model.cpu()\n",
    "\n",
    "# Prepare the input image\n",
    "file = 'C:\\\\Users\\\\MaxwellLee\\\\PycharmProjects\\\\UVSM\\\\yolo-dataset_export_export\\\\test\\\\images\\\\0d9b0bf269.jpg'\n",
    "img = cv2.imread(file)\n",
    "img = cv2.resize(img, (320, 320))\n",
    "\n",
    "rgb_img = img.copy()  # For visual comparison\n",
    "img = np.float32(img) / 255\n",
    "\n",
    "# Extract all layers from the model\n",
    "all_layers = list(model.model.model)  # Access all layers in the model\n",
    "\n",
    "# Create a directory to save heatmaps (optional)\n",
    "import os\n",
    "\n",
    "name = os.path.splitext(os.path.basename(file))[0]\n",
    "output_dir = \"C:\\\\Users\\\\MaxwellLee\\\\PycharmProjects\\\\UVSM\\\\runs\\\\heatmaps\\\\\" + name\n",
    "print(output_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through the first 20 layers and generate heatmaps\n",
    "for i, layer in enumerate(all_layers[-20:]):  # Limit to first 20 layers\n",
    "    print(f\"Processing Layer {i+1}/{min(20, len(all_layers))}: {layer.__class__.__name__}\")\n",
    "\n",
    "    # Use the layer as the target layer\n",
    "    target_layers = [layer]\n",
    "    cam = EigenCAM(model, target_layers, task='od')\n",
    "\n",
    "    # Generate the CAM heatmap\n",
    "    grayscale_cam = cam(rgb_img)[0, :, :]\n",
    "    cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    # Save or display the heatmap\n",
    "    output_path = os.path.join(output_dir, f\"layer_{i+1}_heatmap.jpg\")\n",
    "    Image.fromarray(np.hstack((rgb_img, cam_image))).save(output_path)\n",
    "    print(f\"Saved heatmap for Layer {i+1} to {output_path}\")\n",
    "\n",
    "print(\"Heatmaps generation for first 20 layers complete!\")"
   ],
   "id": "5d717b70402b01c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaxwellLee\\PycharmProjects\\UVSM\\runs\\heatmaps\\0d9b0bf269\n",
      "Processing Layer 1/20: Conv\n",
      "\n",
      "0: 640x640 1 catalytic convertor, 1 fuel tank, 1 silencer, 1 spare tyre, 4 wheels, 145.0ms\n",
      "Speed: 2.0ms preprocess, 145.0ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`k` must be an integer satisfying `0 < k < min(A.shape)`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 48\u001B[0m\n\u001B[0;32m     45\u001B[0m cam \u001B[38;5;241m=\u001B[39m EigenCAM(model, target_layers, task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mod\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# Generate the CAM heatmap\u001B[39;00m\n\u001B[1;32m---> 48\u001B[0m grayscale_cam \u001B[38;5;241m=\u001B[39m \u001B[43mcam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrgb_img\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m, :, :]\n\u001B[0;32m     49\u001B[0m cam_image \u001B[38;5;241m=\u001B[39m show_cam_on_image(img, grayscale_cam, use_rgb\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# Save or display the heatmap\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\UVSM\\yolo_cam\\base_cam.py:208\u001B[0m, in \u001B[0;36mBaseCAM.__call__\u001B[1;34m(self, input_tensor, targets, aug_smooth, eigen_smooth)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m aug_smooth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_augmentation_smoothing(\n\u001B[0;32m    206\u001B[0m         input_tensor, targets, eigen_smooth)\n\u001B[1;32m--> 208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meigen_smooth\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\UVSM\\yolo_cam\\base_cam.py:115\u001B[0m, in \u001B[0;36mBaseCAM.forward\u001B[1;34m(self, input_tensor, targets, eigen_smooth)\u001B[0m\n\u001B[0;32m    104\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward(retain_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    106\u001B[0m \u001B[38;5;66;03m# In most of the saliency attribution papers, the saliency is\u001B[39;00m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;66;03m# computed with a single target layer.\u001B[39;00m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# Commonly it is the last convolutional layer.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# use all conv layers for example, all Batchnorm layers,\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;66;03m# or something else.\u001B[39;00m\n\u001B[1;32m--> 115\u001B[0m cam_per_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_cam_per_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43meigen_smooth\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate_multi_layers(cam_per_layer)\n",
      "File \u001B[1;32m~\\PycharmProjects\\UVSM\\yolo_cam\\base_cam.py:147\u001B[0m, in \u001B[0;36mBaseCAM.compute_cam_per_layer\u001B[1;34m(self, input_tensor, targets, eigen_smooth)\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(grads_list):\n\u001B[0;32m    145\u001B[0m     layer_grads \u001B[38;5;241m=\u001B[39m grads_list[i]\n\u001B[1;32m--> 147\u001B[0m cam \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_cam_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mtarget_layer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mlayer_activations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mlayer_grads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m                         \u001B[49m\u001B[43meigen_smooth\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    153\u001B[0m cam \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmaximum(cam, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    154\u001B[0m scaled \u001B[38;5;241m=\u001B[39m scale_cam_image(cam, target_size)\n",
      "File \u001B[1;32m~\\PycharmProjects\\UVSM\\yolo_cam\\eigen_cam.py:24\u001B[0m, in \u001B[0;36mEigenCAM.get_cam_image\u001B[1;34m(self, input_tensor, target_layer, target_category, activations, grads, eigen_smooth)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_cam_image\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     18\u001B[0m                   input_tensor,\n\u001B[0;32m     19\u001B[0m                   target_layer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     22\u001B[0m                   grads,\n\u001B[0;32m     23\u001B[0m                   eigen_smooth):\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_2d_projection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivations\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\UVSM\\yolo_cam\\utils\\svd_on_activations.py:25\u001B[0m, in \u001B[0;36mget_2d_projection\u001B[1;34m(activation_batch)\u001B[0m\n\u001B[0;32m     23\u001B[0m reshaped_activations \u001B[38;5;241m=\u001B[39m activation_batch\u001B[38;5;241m.\u001B[39mreshape(activation_batch\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     24\u001B[0m reshaped_activations \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m reshaped_activations\u001B[38;5;241m.\u001B[39mmean(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 25\u001B[0m U, S, VT \u001B[38;5;241m=\u001B[39m \u001B[43msvds\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreshaped_activations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Compute only the largest singular vector\u001B[39;00m\n\u001B[0;32m     26\u001B[0m projection \u001B[38;5;241m=\u001B[39m reshaped_activations \u001B[38;5;241m@\u001B[39m VT[\u001B[38;5;241m0\u001B[39m, :]\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m projection\u001B[38;5;241m.\u001B[39mreshape(activation_batch\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:])\n",
      "File \u001B[1;32m~\\PycharmProjects\\UVSM\\newvenv\\lib\\site-packages\\scipy\\sparse\\linalg\\_eigen\\_svds.py:438\u001B[0m, in \u001B[0;36msvds\u001B[1;34m(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors, solver, random_state, options)\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msvds\u001B[39m(A, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m, ncv\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, tol\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, which\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLM\u001B[39m\u001B[38;5;124m'\u001B[39m, v0\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    100\u001B[0m          maxiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, return_singular_vectors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    101\u001B[0m          solver\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124marpack\u001B[39m\u001B[38;5;124m'\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    102\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;124;03m    Partial singular value decomposition of a sparse matrix.\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    436\u001B[0m \n\u001B[0;32m    437\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 438\u001B[0m     args \u001B[38;5;241m=\u001B[39m \u001B[43m_iv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mncv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhich\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxiter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_singular_vectors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    439\u001B[0m \u001B[43m               \u001B[49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    440\u001B[0m     (A, k, ncv, tol, which, v0, maxiter,\n\u001B[0;32m    441\u001B[0m      return_singular_vectors, solver, random_state) \u001B[38;5;241m=\u001B[39m args\n\u001B[0;32m    443\u001B[0m     largest \u001B[38;5;241m=\u001B[39m (which \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLM\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\UVSM\\newvenv\\lib\\site-packages\\scipy\\sparse\\linalg\\_eigen\\_svds.py:44\u001B[0m, in \u001B[0;36m_iv\u001B[1;34m(A, k, ncv, tol, which, v0, maxiter, return_singular, solver, random_state)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mint\u001B[39m(k) \u001B[38;5;241m!=\u001B[39m k \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m k \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m kmax):\n\u001B[0;32m     43\u001B[0m     message \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`k` must be an integer satisfying `0 < k < min(A.shape)`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message)\n\u001B[0;32m     45\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(k)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# input validation/standardization for `ncv`\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: `k` must be an integer satisfying `0 < k < min(A.shape)`."
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ################## SHOW ALL LAYERS OF SAVED HEATMAP (ASCENDING ORDER) ##################\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_numeric_part(filename):\n",
    "    # Extract numeric part from the filename (assuming the numeric part is at the end of the filename before extension)\n",
    "    return int(''.join(filter(str.isdigit, filename)))  # Extract digits and convert to integer\n",
    "\n",
    "image_path = \"heatmaps/0e9dd3deea\"\n",
    "\n",
    "# List all files in the 'heatmaps' directory\n",
    "image_files = os.listdir(image_path)\n",
    "\n",
    "# Sort files numerically using the custom sorting function\n",
    "image_files.sort(key=extract_numeric_part)\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for image_name in image_files:\n",
    "    image_file_path = os.path.join(image_path, image_name)  # Create full path to the image file\n",
    "    if os.path.isfile(image_file_path):  # Check if it's a file\n",
    "        im = cv2.imread(image_file_path)  # Read the image\n",
    "        print(f\"{image_file_path}\")\n",
    "\n",
    "        if im is not None:\n",
    "            # Convert BGR to RGB (OpenCV loads images in BGR by default)\n",
    "            im_rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Set the figure size to enlarge the image (width, height in inches)\n",
    "            plt.figure(figsize=(12.8, 6.4))  # You can adjust these values to your preference\n",
    "            \n",
    "            # Display image using matplotlib\n",
    "            plt.imshow(im_rgb)\n",
    "            plt.axis('off')  # Hide axes\n",
    "            plt.show()  # Show the image in the notebook\n",
    "        else:\n",
    "            print(f\"Failed to load image: {image_file_path}\")"
   ],
   "id": "76aaa90706aa3d39",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
